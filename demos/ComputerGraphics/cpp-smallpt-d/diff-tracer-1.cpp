//--------------------------------------------------------------------*- C++ -*-
// clad - The C++ Clang-based Automatic Differentiator
//
// Demo application of a simple gradient descent algorithm to find
// some params (one sphere position) in ray traced 3D scene.
// Clad is used to calculate the gradient of the cost function.
// Cost function is calculated as norm of differece between two images -
// first is target image and second is interemediate image generated
// during gradient decent algorithm.
//
//----------------------------------------------------------------------------//

// To run the demo please type:
// path/to/clang  -Xclang -add-plugin -Xclang clad -Xclang -load -Xclang \
// path/to/libclad.so  -I../include/ -x c++ -lstdc++ -lm diff-tracer-1.cpp
//
// A typical invocation would be:
// ../../../../obj/Debug+Asserts/bin/clang  -Xclang -add-plugin -Xclang clad \
// -Xclang -load -Xclang ../../../../obj/Debug+Asserts/lib/libclad.dylib     \
// -I../include/ -x c++ -lstdc++ -lm diff-tracer-1.cpp
//
// To plot the results:
// Results are stored in images: image-target.ppm, and image-i-(0..N).ppm

//#include <fstream>  // For plotting data.
//#include <iostream> // For std::*
//#include <vector>   // For std::vector.

// Necessary for clad to work include
#include "clad/Differentiator/Differentiator.h"

// Include traces as embed "library" of functions
#define CPP_EMBED_SMALLPT 1
#include "cpp-smallpt.cpp"

using namespace smallpt;

// Structure to represent input dataset
// w and h - represetn width and height of images
// target, current - represents the input/target and
// output data/images respectively
struct Dataset {
  const std::uint32_t w = 1024u;
  const std::uint32_t h = 768u;
  const std::uint32_t nb_samples;
  Vector3* target;
  Vector3* current;
  double learning_rate = 1e-2;
  // result
  double Vx, Vy, Vz;
  int step = 0;

  // Populate the data with target image (render example + random noice)
  Dataset(const std::uint32_t nb_samples = 1, const std::uint32_t w = 1024u, const std::uint32_t h = 768u) :
    nb_samples(nb_samples), w(w), h(h) {
    // Create Target data/image
    char fileName[4096];
    snprintf(fileName, sizeof(fileName), "image-target.ppm");
    target = new Vector3[w*h];
    current = new Vector3[w*h];
    Render(
      scene, *(&scene + 1) - scene, // Geometry, Lights
      27, 16.5, 47, // Params - Center of one sphere // must be Vector3()
      w, h, nb_samples, 0, // Camera
      target, fileName // Result
    );

    // For initial position of sphere we use randomized values
    Vx = 80.0 * (((double)std::rand())/RAND_MAX) + 10.0;
    Vy = 80.0 * (((double)std::rand())/RAND_MAX) + 10.0;
    Vz = 80.0 * (((double)std::rand())/RAND_MAX) + 10.0;
  }
};

// Function to perform a minimization step
// theta_x are the hypothesis parameters, dt is the generated dataset and
// clad_grad is the gradient function generated by Clad
template <typename T>
void performStep(double& theta_0, double& theta_1, double& theta_2, Dataset dt, T clad_grad) {
  double J_theta[3+2];
  double result[3] = {0, 0, 0};
  // current?
  for (size_t i = 0; i < dt.w*dt.h; i++) {
    J_theta[0] = J_theta[1] = J_theta[2] = J_theta[3] = 0;
//    clad_grad.execute(theta_0, theta_1, theta_2, dt.target[i], dt.current[i],
//        &J_theta[0], &J_theta[1], &J_theta[2], &J_theta[3], &J_theta[4]
//    );

    result[0] += J_theta[0];
    result[1] += J_theta[1];
    result[2] += J_theta[2];
  }

  theta_0 -= dt.learning_rate * result[0] / (2 * dt.w*dt.h);
  theta_1 -= dt.learning_rate * result[1] / (2 * dt.w*dt.h);
  theta_2 -= dt.learning_rate * result[2] / (2 * dt.w*dt.h);
}

// The cost function to minimize using gradient descent
// theta_x are the parameters to learn; x, y are the inputs and outputs of f
double cost(double theta_0, double theta_1, double theta_2, Dataset dt) {
  char fileName[4096];
  snprintf(fileName, sizeof(fileName), "image-%d.ppm", dt.step++);
  Render(
      scene, *(&scene + 1) - scene, // Geometry, Lights
      dt.Vx, dt.Vy, dt.Vz, // Params - Center of one sphere // must be Vector3()
      dt.w, dt.h, dt.nb_samples, 0, // Camera
      dt.current, fileName // Result
    );
  for (int i=0; i<=dt.h; i++) {
    for (int j=0; j<=dt.w; j++) {
//      sum += 
    }
  }

//  double f_x = f(theta_0, theta_1, theta_2, x);
//  return (f_x - y) * (f_x - y);
  return 0;
}

double f(double x, double y) {
  double t = 0;
  for (int i=0; i<10; i++) {
    t += x*y;
  }
  return t;
}

double f1(double x[], int cnt) {
  double sum = 0;
  for (int i=0; i<cnt; i++) {
    sum += x[i];
  }
  return sum;
}

// Function to optimize the cost function of interest
// theta is the hypothesis parameter list and maxSteps is the maximum steps to
// perform
void optimize(double theta[3], Dataset dt, unsigned int maxSteps, double eps) {
  auto diff = theta;
  bool hasConverged = false;
  int currentStep = 0;

  // Call for Clad to differentiate the cost function specified before
  auto clad_grad = clad::gradient(cost);

  do {
    performStep(theta[0], theta[1], theta[2], dt, clad_grad);

    std::cout << "Steps #" << currentStep << " Theta 0: " << theta[0]
              << " Theta 1: " << theta[1] << " Theta 2: " << theta[2] << std::endl;

    hasConverged = abs(diff[0] - theta[0]) <= eps &&
                   abs(diff[1] - theta[1]) <= eps &&
                   abs(diff[2] - theta[2]) <= eps;

    diff = theta;
  } while (currentStep++ < maxSteps && !hasConverged);
}

int main(int argc, char* argv[]) {
  const std::uint32_t nb_samples = (2 == argc) ? atoi(argv[1]) / 4 : 1;

auto f_dx = clad::differentiate(f, "x");
auto f_dy = clad::differentiate(f, "y");
auto f_g = clad::gradient(f);

auto f1_dx = clad::differentiate(f1, "x[0]");
auto f1_g = clad::gradient(f1);

  Dataset dt(nb_samples, 1024u, 768u);
  double theta[] = {dt.Vx, dt.Vy, dt.Vz};
  optimize(theta, dt, 10000, 1e-6);

  std::cout << "Result: "
            << "(" << theta[0] << ", " << theta[1] << ", " << theta[2] << ")" << std::endl;

  return 0;
}
/*
double f(double x, double y) {
  double t = 0;
  for (int i=0; i<10; i++) {
    t += x*y;
  }
  return t;
}

double f_dx(double x, double y) {
  double t = 0;
  for (int i=0; i<cnt; i++) {
    t += y;
  }
  return t;
}

double f_dy(double x, double y) {
  double t = 0;
  for (int i=0; i<cnt; i++) {
    t += x;
  }
  return t;
}

double f_darg0(double x, double y) {
    double _d_x = 1;
    double _d_y = 0;
    double _d_t = 0;
    double t = 0;
    {
        int _d_i = 0;
        for (int i = 0; i < 10; i++) {
            _d_t += _d_x * y + x * _d_y;
            t += x * y;
        }
    }
    return _d_t;
}

double f_darg1(double x, double y) {
    double _d_x = 0;
    double _d_y = 1;
    double _d_t = 0;
    double t = 0;
    {
        int _d_i = 0;
        for (int i = 0; i < 10; i++) {
            _d_t += _d_x * y + x * _d_y;
            t += x * y;
        }
    }
    return _d_t;
}

void f_grad(double x, double y, clad::array_ref<double> _d_x, clad::array_ref<double> _d_y) {
    double _d_t = 0;
    unsigned long _t0;
    int _d_i = 0;
    clad::tape<double> _t1 = {};
    clad::tape<double> _t2 = {};
    double t = 0;
    _t0 = 0;
    for (int i = 0; i < 10; i++) {
        _t0++;
        t += clad::push(_t2, x) * clad::push(_t1, y);
    }
    double f_return = t;
    goto _label0;
  _label0:
    _d_t += 1;
    for (; _t0; _t0--) {
        {
            double _r_d0 = _d_t;
            _d_t += _r_d0;
            double _r0 = _r_d0 * clad::pop(_t1);
            * _d_x += _r0;
            double _r1 = clad::pop(_t2) * _r_d0;
            * _d_y += _r1;
            _d_t -= _r_d0;
        }
    }
}

void f_g(double x, double y, double result[2]) {
  double t_x = 0;
  double t_y = 0;
  for (int i=0; i<cnt; i++) {
    t_x += x;
    t_y += y;
  }
  result[0] = t_x;
  result[1] = t_y;
}

void f1(double x[], int cnt, double dx[]) {
  double sum = 0;
  for (int i=0; i<cnt; i++) {
    sum += x[i]*x[i];
  }
  return sum;

  double sum_0 = 0;
  double sum_1 = 0;
  for (int i=0; i<cnt; i++) {
    sum_0 += (i==0) * 2*x[i];
    sum_1 += (i==1) * 2*x[i];
  }
  dx[0] = sum_0;
  dx[1] = sum_1;
}


*/